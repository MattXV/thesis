\chapter{Conclusion}\label{ch:Conclusion}

The primary goal of this thesis has been to explore a novel system for acoustic rendering bespoke to \acrshort{ar} platforms, enabling context-aware rendering to consider characteristics of the environment surrounding the player. The objectives defined by this thesis developed and evaluated individual systems composing the pipeline proposed as a solution modularised into standalone contributions. Overall, the development of components evaluations conducted on test cases showed that the domain of acoustic rendering for \acrshort{ar} would benefit from applications of acoustic rendering pipelines, and the discussions on the results gathered open several potential avenues for future research heading towards more interactive and realistic auditory interactions.

\section{Summary}
The following Sections will reflect on the objectives posed by the introductory chapter of this work (Section~\ref{sec:thesis-objectives}), highlighting significant results by connecting findings gathered from studies conducted throughout the development of the pipeline. For contextualisation, clarity, and accessibility, Table~\ref{tab:objectives-contributions} summarises the thesis aims and how Chapters contribute to each objective.
\input{objectives-contributions}

Overall, the significance of this thesis work lies in the proposal of a novel rendering pipeline, expressed by Chapter~\ref{ch:ar-pipeline}, which illustrates a design of the end-to-end system, targeting the primary objective, illustrating its concept and design principles, demonstrating implementations and apparatus design, and outlining the vision and potential expansions.\par
Chapter\ref{ch:Evaluation} evaluated a prototype deployed to an \acrshort{ar} platform, evaluating psychoacoustic factors in auditory displays, demonstrating the validity of the overarching aim by proving that a pipeline for realistic auditory displays has effects on interactions in virtual environments. 

\begin{itemize}
    \item objective of each chapter
    \item conclusions relating to each chapter
    \item key findings
\end{itemize}

\section{Towards Integrating Computer Vision into Audio Augmented Reality}
As a high-level discussion around the interpreted results gathered from evaluating the system and its components, there are conclusions drawn that determine contributions towards the field of \acrfull{aar} and domains of computer graphics and vision in the context of simulating soundfields and generating realistic auditory stimuli. The following Sections will break these down, discussing their relevance to the broader research domains, target use cases, as well as their limitations, and how future work has the potential to overcome them.

\begin{itemize}
    \item contributions in terms of methodologies presented
    \item novel testing techniques
    \item integrations of CDPAM into testing
    \item application to real-world examples 
    \item measuring user performance
\end{itemize}

\subsection{System Overview}
The primary contributions provided by the work on 
it uses geometrical acoustics-based acoustic rendering techniques. It should look at leveraging modern radiance field approaches.

\subsection{Acoustic Characteristics Retrieval Methods}
The solutions proposed addressed the problem of extracting soundscape features in context-aware acoustic rendering target platforms equipped with space-sensing technology. The two proposed novel systems addressed the problem of retrieving acoustic characteristics from environments from their visual representations by adopting computer vision techniques. This thesis work and recent methods show that such a task is still an open research question due to the complexity in the mappings between visual representations of space and auditory stimuli generated from simulated soundfields based on properties assigned from inferring their visual appearance.\par
Mapping acoustic properties to representations of space has been defined in this work as the ``material tagging'' process, expressing the task engineers face when constructing immersive, complex scenes in game engines, where portions of scene geometry are assigned acoustic material properties. As acoustic simulations become more feasible for increasing use cases and applications, material tagging will incur higher manual authoring, which the application of computer vision techniques can automate, enabling and rendering procedural workflows.\par
There are benefits to the two proposed systems that aim at automating material tagging. With the camera-based acoustic material tagging system demonstrated in Section~\ref{sec:camera-tagging}, a novel system that uses camera renders to infer portions of scene geometry they depict, provides a solution that can adapt to cameras equipped by \acrshortpl{hmd}. It allows the system to scan and map acoustic characteristics to the environments as the user walks around their \acrshort{ar} scene.


The texture-based alternative system demonstrated in Section~\ref{sec:texture-tagging} expanded towards a more efficient workflow that also has applications to \acrshortpl{hmd} by using spatial reconstruction systems that provide and update scene geometry as the user navigates the scene.


\subsection{Acoustic Rendering}
Geometrical acoustics-based rendering pipelines benefit from controlling the number of rays and other aspects associated with the simulated acoustic phenomena. Thus, perceptual evaluations aimed at measuring psychoacoustic factors associated with auditory stimuli produced from simulated soundfields benefit from control over the resolution of the sound propagation technique. The degree of control is crucial for evaluating perceptual responses and defining the minimum requirements for psychoacoustic factors of the generated stimuli.\par

\subsection{Psychoacoustic and Human Factors}

\section{Limitations}
There are limitations around findings obtained from the study.

Despite Chapter~\ref{ch:Evaluation} demonstrating the validity of the overarching aim of the thesis, some limitations require addressing to generalise towards a unified model for auditory interactions in \acrshort{ar}.

\begin{itemize}
    \item prototype limited to offline rendering
    \item sound rendering based on geometrical acoustics
    \item computer vision techniques applied to a variety of spaces
    \item computer vision techniques applied to a variety of sound renderers
    \item psychoacoustic testing has limited generalisability
\end{itemize}

\section{Future Work}

\subsection{Visual-Acoustic Mappings}
\begin{itemize}
    \item An extended Image2Reverb that integrates listener and speaker positions in the mapping process.
\end{itemize}

Fast image-to-image network to manipulate existing IRs by using depth maps. Input IRs model the acoustic phenomena of the environment. The network learns how to manipulate input frequency-dependent IRs based on a depth map: e.g., an obstacle between emitter and receiver affects high-frequency reflections.

\subsection{Materials}
\begin{itemize}
    \item A material optimiser based on ground truth RIRs and an agent tasked with painting surfaces with the correct materials.
    \item Unsupervised methods for material recognition using synthetic data to improve the workflow of expanding mappings between acoustic material databases and their appearance.
    \item Ablation study on material recognition pipelines
\end{itemize}

\subsection{Perceptual Response Analysis}
Chapter~\ref{ch:ch:acousticrendering} conducts extensive testing on the acoustic rendering pipeline employed by the \acrshort{ar} prototype and analyses objective and subjective factors of simulated soundfields. However, some unexplored avenues could expand the testing conducted, providing generalised guidelines for future sound rendering methods. A crucial expansion point here is the definition of a minimum input to a rendering pipeline to obtain a perceptually valid response --- an investigation that could be performed both on \acrshort{ga} and deep learning-based acoustic rendering systems.\par
Future work should analyse the minimum number of  \acrshort{ga} pipelines

\begin{itemize}
    \item Perceptual analysis of geometry reduction processes.
\end{itemize}

\subsection{Further Psychoacoustic Analysis}


\begin{itemize}
    \item Ablation study for the resolution of generated acoustic responses
\end{itemize}

\section{Conclusive Remarks}
This thesis work builds on decades of advances towards systems for realistic auditory interactions for immersive media, adopting classic techniques for simulating soundfields and leveraging recent works within the domains of graphics and vision to optimise and automate several tasks associated with rendering believable auditory displays.\par
The primary goal of researching and proposing a novel system for \acrshort{ar} platforms was achieved, grounding its design choices on data collected from a series of experimental tests.